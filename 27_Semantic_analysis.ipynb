{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0/6hNMUNU8isSLpmUsHxb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varshitha5072/nlp/blob/main/27_Semantic_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoB6IoqAGfzv",
        "outputId": "90076fa5-db0d-4e40-be54-0279284e49c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved documents (in order of relevance):\n",
            "Document 1: Climate change is a pressing global issue that requires immediate action.\n",
            "Document 4: The Paris Agreement is an international treaty aimed at addressing climate change.\n",
            "Document 5: Sustainability and environmental conservation are crucial for the future of our planet.\n",
            "Document 3: Greenhouse gases, like carbon dioxide and methane, contribute to global warming.\n",
            "Document 2: Renewable energy sources, such as solar and wind power, are essential for reducing carbon emissions.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.chunk import ne_chunk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "# Define the sentences\n",
        "sentences = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"She is an excellent chef and loves to cook delicious meals.\",\n",
        "    \"The Eiffel Tower in Paris is a famous landmark.\"\n",
        "]\n",
        "\n",
        "# Function to extract noun phrases and their meanings\n",
        "def extract_noun_phrases_meanings(sentences):\n",
        "    for sentence in sentences:\n",
        "        # Tokenize the sentence\n",
        "        words = word_tokenize(sentence)\n",
        "\n",
        "        # Perform Part-of-Speech (POS) tagging\n",
        "        pos_tags = pos_tag(words)\n",
        "\n",
        "        # Perform chunking to extract noun phrases\n",
        "        chunks = ne_chunk(pos_tags)\n",
        "\n",
        "        # Extract noun phrases and their meanings\n",
        "        noun_phrases = []\n",
        "        meanings = []\n",
        "        for chunk in chunks:\n",
        "            if hasattr(chunk, 'label') and chunk.label() == 'NP':\n",
        "                noun_phrase = ' '.join([token for token, pos in chunk.leaves()])\n",
        "                noun_phrases.append(noun_phrase)\n",
        "\n",
        "                # Define meanings (for demonstration purposes)\n",
        "                # In a real-world application, meanings might be retrieved from a knowledge base or database\n",
        "                if 'Eiffel Tower' in noun_phrase:\n",
        "                    meanings.append(\"A famous landmark in Paris, France.\")\n",
        "                elif 'chef' in noun_phrase:\n",
        "                    meanings.append(\"Someone skilled in cooking.\")\n",
        "                else:\n",
        "                    meanings.append(\"Meaning not defined.\")\n",
        "\n",
        "        # Display extracted noun phrases and their meanings\n",
        "        print(f\"Sentence: {sentence}\")\n",
        "        print(\"Extracted Noun Phrases:\")\n",
        "        for i, noun_phrase in enumerate(noun_phrases):\n",
        "            print(f\"{i + 1}. {noun_phrase}\")\n",
        "            print(f\"   Meaning: {meanings[i]}\")\n",
        "        print(\"\")\n"
      ]
    }
  ]
}